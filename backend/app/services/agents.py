from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.messages import SystemMessage, HumanMessage
from .rag_engine import get_retriever

# --- 1. CONFIGURA√á√ÉO DAS PERSONALIDADES (C√âREBROS DIFERENTES) ---
prompts_foco = {
    "Devocional": (
        "Voc√™ √© uma mentora espiritual carinhosa e acolhedora. "
        "Sua linguagem deve ser po√©tica, reconfortante e simples. "
        "Foque na aplica√ß√£o pessoal, na paz interior e no amor de Deus. "
        "Evite termos t√©cnicos teol√≥gicos dif√≠ceis. "
        "Seu objetivo principal √© aquecer o cora√ß√£o do usu√°rio e inspirar f√©."
    ),
    "Teol√≥gico": (
        "Voc√™ √© uma professora de teologia acad√™mica, precisa e profunda. "
        "Foque na exegese b√≠blica, no contexto hist√≥rico-cultural, nos significados originais (grego/hebraico) e na doutrina s√≥lida. "
        "Use linguagem culta e explique termos profundos. "
        "Cite refer√™ncias cruzadas e conex√µes hist√≥ricas quando poss√≠vel."
    ),
    "Pastoral": (
        "Voc√™ √© uma conselheira crist√£ experiente em vida pr√°tica, psicologia e relacionamentos. "
        "Seja emp√°tica, mas direta e orientada para a a√ß√£o. "
        "N√£o fique apenas na teoria; foque em como aplicar princ√≠pios b√≠blicos para resolver conflitos reais, "
        "lidar com emo√ß√µes dif√≠ceis (ansiedade, ira, luto) e tomar decis√µes s√°bias no dia a dia."
    )
}

# --- 2. SUPERVISOR (DECIDE A ROTA) ---
def get_supervisor_chain():
    # Mantemos o Llama 3 com temperatura 0 para ser preciso na decis√£o
    llm = ChatGroq(model_name="llama-3.3-70b-versatile", temperature=0)
    
    system = """
    Voc√™ √© um classificador de inten√ß√£o. Responda APENAS com uma das palavras abaixo:
    - BIBLIA (se a pergunta for sobre vers√≠culos, doutrina, teologia ou conselho espiritual)
    - DICIONARIO (se a pergunta for pedindo o significado de uma palavra espec√≠fica)
    - WEB (se for sobre fatos atuais, not√≠cias ou algo que n√£o est√° na b√≠blia)
    """
    return ChatPromptTemplate.from_messages([("system", system), ("human", "{input}")]) | llm | StrOutputParser()

# --- 3. AGENTE WEB (PARA COISAS ATUAIS) ---
def get_agente_web(pergunta, chat_history, foco):
    search = DuckDuckGoSearchRun()
    try:
        resultados = search.run(pergunta)
    except:
        resultados = "Sem acesso √† web no momento."

    # Llama 3 (Temperatura m√©dia para criatividade controlada)
    llm = ChatGroq(model_name="llama-3.3-70b-versatile", temperature=0.5)
    
    # Seleciona a personalidade baseada no Foco escolhido no Frontend
    # Se der erro ou n√£o achar, usa o Devocional como padr√£o
    personalidade = prompts_foco.get(foco, prompts_foco["Devocional"])
    
    sys_msg = (
        f"{personalidade}\n\n"
        f"Contexto obtido da Web: {resultados}.\n"
        "Responda √† d√∫vida do usu√°rio com base nisso, mantendo sua personalidade crist√£.\n"
        "Ao final da resposta, pule uma linha e escreva obrigatoriamente:\n"
        "'üìñ **Leitura Recomendada:**' seguido de um vers√≠culo ou cap√≠tulo b√≠blico relacionado ao tema."
    )
    
    msgs = [SystemMessage(content=sys_msg)] + chat_history + [HumanMessage(content=pergunta)]
    return llm.invoke(msgs).content, "Web Search"

# --- 4. AGENTE RAG (ESPECIALISTA EM B√çBLIA) ---
def get_agente_rag(rota, pergunta, chat_history, foco):
    # Llama 3 (Temperatura m√©dia)
    llm = ChatGroq(model_name="llama-3.3-70b-versatile", temperature=0.5)
    
    namespace = "dicionario_teologico" if rota == "DICIONARIO" else "biblia_sagrada"
    retriever = get_retriever(namespace)
    
    contexto = ""
    if retriever:
        try:
            docs = retriever.invoke(pergunta)
            contexto = "\n".join([d.page_content for d in docs])
        except: pass

    # Seleciona a personalidade baseada no Foco
    personalidade = prompts_foco.get(foco, prompts_foco["Devocional"])

    sys_msg = (
        f"{personalidade}\n\n"
        f"Use este contexto b√≠blico/teol√≥gico para embasar sua resposta: {contexto}.\n"
        "Se o contexto for insuficiente, use seu conhecimento geral, mas mantenha a fidelidade b√≠blica.\n"
        "Ao final da resposta, pule uma linha e escreva obrigatoriamente:\n"
        "'üìñ **Leitura Recomendada:**' seguido de um vers√≠culo ou cap√≠tulo b√≠blico chave para o usu√°rio meditar."
    )

    msgs = [SystemMessage(content=sys_msg)] + chat_history + [HumanMessage(content=pergunta)]
    return llm.invoke(msgs).content, "Rag Engine"